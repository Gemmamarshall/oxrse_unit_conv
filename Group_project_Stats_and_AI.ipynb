{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gemmamarshall/oxrse_unit_conv/blob/main/Group_project_Stats_and_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9h4GFe7axukt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "85d582e7-cfc6-4d51-a66d-4669f51e7b2c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'esm'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2642256595.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m###### load ESM and extract embeddings for sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mesm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'esm'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# # Create environment\n",
        "# conda create -n esmc_env python=3.10 -y\n",
        "# conda activate esmc_env\n",
        "\n",
        "# # Install PyTorch CPU version\n",
        "# pip install torch --index-url https://download.pytorch.org/whl/cpu\n",
        "# or conda install pytorch-cpu torchvision-cpu -c pytorch\n",
        "\n",
        "# # Install ESM package (ESMC is part of esm)\n",
        "# pip install esm\n",
        "\n",
        "# # Install other utilities\n",
        "# pip install numpy pandas scikit-learn matplotlib seaborn\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Replace with 50+ sequences and polarity measurements\n",
        "data = {\n",
        "    \"protein_id\": [\"P1\",\"P2\",\"P3\",\"P4\",\"P5\"],\n",
        "    \"sequence\": [\n",
        "        \"MSTNPKPQRIT\",\n",
        "        \"MLAIKAGFAT\",\n",
        "        \"VDSDDQEQVI\",\n",
        "        \"MNKQWERTYI\",\n",
        "        \"MKLFIAGVLA\"\n",
        "    ],\n",
        "    \"polarity\": [-40, 20, 5, 50, -10]  # -50 = back, 50 = front\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "\n",
        "##############################################################\n",
        "###### load ESM and extract embeddings for sequences\n",
        "import torch\n",
        "import esm\n",
        "import numpy as np\n",
        "\n",
        "# Load pretrained ESM Cambrian model (CPU only)\n",
        "model, alphabet = esm.pretrained.esmc_300M()\n",
        "model.eval()  # inference mode\n",
        "device = torch.device(\"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "\n",
        "mean_embeddings = []        # per-protein embedding\n",
        "per_residue_embeddings = [] # per-residue embeddings\n",
        "sequence_lengths = []\n",
        "\n",
        "for seq in df[\"sequence\"]:\n",
        "    batch_labels, batch_strs, batch_tokens = batch_converter([(\"protein\", seq)])\n",
        "    batch_tokens = batch_tokens.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        results = model(batch_tokens, repr_layers=[model.num_layers], return_contacts=False)\n",
        "\n",
        "    # Per-residue embeddings: shape = (L, D)\n",
        "    token_embeddings = results[\"representations\"][model.num_layers][0, 1:len(seq)+1]  # remove start token\n",
        "    per_residue_embeddings.append(token_embeddings.cpu().numpy())\n",
        "    sequence_lengths.append(len(seq))\n",
        "\n",
        "    # Per-protein embedding: mean over residues\n",
        "    mean_embeddings.append(token_embeddings.mean(0).cpu().numpy())\n",
        "\n",
        "X = np.vstack(mean_embeddings)  # shape = n_proteins × embedding_dim\n",
        "y = df[\"polarity\"].values\n",
        "print(\"Embedding shape:\", X.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### train regression model on per-protein embeddings\n",
        "\n",
        "# You have per-protein embeddings: each protein is summarized by a single vector of numbers (mean_embedding from all residues).\n",
        "\n",
        "# You train a regression model:\n",
        "# Polarity=Regressor(mean_embedding)\n",
        "# Each dimension in the embedding vector is a learned feature by the model (ESM‑2 or ESMC).\n",
        "# The regression weight tells you:\n",
        "# “If this embedding dimension increases, how much does the polarity score change?”\n",
        "# Positive weight goes to increases polarity (toward +50)\n",
        "# Negative weight goes to decreases polarity (toward -50)\n",
        "# Larger absolute value → more influence on the polarity prediction\n",
        "\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale embeddings\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# LASSO regression for interpretability\n",
        "reg = Lasso(alpha=0.001)\n",
        "reg.fit(X_scaled, y)\n",
        "\n",
        "print(\"Top embedding dimensions influencing polarity:\", np.argsort(np.abs(reg.coef_))[::-1][:10])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### compute each residues importance\n",
        "# Now you want residue-level interpretation:\n",
        "# You know which embedding dimensions are important (from reg.coef_).\n",
        "# Each residue embedding also has the same dimensions.\n",
        "# Multiply the per-residue embedding by the regression weights:\n",
        "# Residue contribution=residue_embedding⋅regression_weights\n",
        "# This gives a score per residue\n",
        "# High absolute values → this amino acid strongly drives the polarity prediction\n",
        "\n",
        "per_residue_contributions = []\n",
        "\n",
        "for emb in per_residue_embeddings:\n",
        "    # emb shape: (L, D)\n",
        "    contribution = emb @ reg.coef_  # shape: (L,)\n",
        "    per_residue_contributions.append(contribution)\n",
        "\n",
        "\n",
        "\n",
        "### aggregate across all proteins\n",
        "    # Option 1: average by residue position (if aligned lengths) or concatenate all residues\n",
        "all_contributions = np.concatenate(per_residue_contributions)\n",
        "print(\"All residues contribution shape:\", all_contributions.shape)\n",
        "\n",
        "# # Identify top residues (largest absolute contribution)\n",
        "# top_indices = np.argsort(np.abs(all_contributions))[::-1][:20]\n",
        "# print(\"Top 20 residues driving polarity across all proteins:\", top_indices)\n",
        "\n",
        "\n",
        "### Plot per residue contribution per protein on polarity score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "seq_idx = 0  # first protein\n",
        "seq = df[\"sequence\"][seq_idx]\n",
        "contrib = per_residue_contributions[seq_idx]\n",
        "\n",
        "plt.figure(figsize=(8,3))\n",
        "plt.bar(range(len(seq)), contrib)\n",
        "plt.xticks(range(len(seq)), list(seq))\n",
        "plt.xlabel(\"Residue\")\n",
        "plt.ylabel(\"Contribution to polarity\")\n",
        "plt.title(f\"Residue contributions for {df['protein_id'][seq_idx]}\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "## plot heatmap of per residue contributions\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "for i, contrib in enumerate(per_residue_contributions):\n",
        "    sns.heatmap([contrib], cmap=\"coolwarm\", cbar=True, xticklabels=list(df['sequence'][i]))\n",
        "plt.xlabel(\"Residue position\")\n",
        "plt.ylabel(\"Proteins\")\n",
        "plt.title(\"Per-residue contributions to polarity across all proteins\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Other experiments: Clustering / dimensionality reduction of embeddings\n",
        "# Use per-protein embeddings to:\n",
        "# Reduce dimensionality (PCA, t-SNE, UMAP)\n",
        "# Cluster proteins by similarity in embedding space\n",
        "\n",
        "# Goal: see whether proteins with similar organization, polarity, or subcellular localization naturally cluster\n",
        "\n",
        "# Insight: groups of sequences may share structural motifs or charged patterns influencing organization.\n",
        "\n",
        "# Other experiments 2: Sequence motif discovery\n",
        "# From high-contribution residues, find contiguous motifs or patterns enriched in top residues.\n",
        "# Methods:\n",
        "# Scan for charged clusters, hydrophobic stretches, or conserved motifs\n",
        "# Use alignment tools to find motifs conserved across similar proteins\n",
        "# Outcome: candidate functional or structural elements responsible for cellular localization or polarity.\n",
        "\n",
        "# Follow up: Motif enrichment / functional annotation\n",
        "# Take top motifs identified from per-residue contributions and check:\n",
        "# Known functional domains (Pfam, InterPro)\n",
        "# Post-translational modifications (phosphorylation, lipidation)\n",
        "# Could link sequence patterns to mechanistic drivers of polarity\n",
        "\n",
        "# Follow up: Map important residues\n",
        "# PDB structures (or AlphaFold models)\n",
        "# map sequences flagged up as important to polarity onto structure\n",
        "# Goal: see whether key residues cluster in certain domains (e.g., membrane-binding face, coiled regions, hydrophobic, charged, IDRs).\n",
        "\n",
        "# Follow up: Predict organisation of other surface proteins\n",
        "# With the regression model - you can use this predict where non quantified proteins are e.g., If your model works well - it should say that the receptor ICAM-2 goes to uropod too."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# do this firs before anything\n",
        "# Import the package\n",
        "import sys\n",
        "!{sys.executable} -m pip install git+https://github.com/David-Araripe/UniProtMapper.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeyI47II1uLq",
        "outputId": "af347040-78ca-4641-8c64-071075de0d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/David-Araripe/UniProtMapper.git\n",
            "  Cloning https://github.com/David-Araripe/UniProtMapper.git to /tmp/pip-req-build-04bimo2j\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/David-Araripe/UniProtMapper.git /tmp/pip-req-build-04bimo2j\n",
            "  Resolved https://github.com/David-Araripe/UniProtMapper.git to commit d7054f6df37423cbcd4bb24bf91385dbba2528df\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from uniprot-id-mapper==1.1.5.dev1+gd7054f6df) (2.32.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from uniprot-id-mapper==1.1.5.dev1+gd7054f6df) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from uniprot-id-mapper==1.1.5.dev1+gd7054f6df) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from uniprot-id-mapper==1.1.5.dev1+gd7054f6df) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->uniprot-id-mapper==1.1.5.dev1+gd7054f6df) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->uniprot-id-mapper==1.1.5.dev1+gd7054f6df) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->uniprot-id-mapper==1.1.5.dev1+gd7054f6df) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->uniprot-id-mapper==1.1.5.dev1+gd7054f6df) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->uniprot-id-mapper==1.1.5.dev1+gd7054f6df) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->uniprot-id-mapper==1.1.5.dev1+gd7054f6df) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->uniprot-id-mapper==1.1.5.dev1+gd7054f6df) (2025.11.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->uniprot-id-mapper==1.1.5.dev1+gd7054f6df) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is to understand the basics behind the uniprotmapper whihc might be helpful\n",
        "from UniProtMapper import ProtMapper\n",
        "\n",
        "mapper = ProtMapper()\n",
        "result, failed = mapper.get(\n",
        "    ids=[\"P30542\", \"Q16678\", \"Q02880\"],\n",
        "    from_db=\"UniProtKB_AC-ID\",\n",
        "    to_db=\"Ensembl\",\n",
        ")\n",
        "print(result.head())\n",
        "print(\"failed:\", failed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHl_W6JHVBfl",
        "outputId": "8550ca02-39d1-4ae3-bc47-386c3de9d1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched: 3 / 3\n",
            "     From                  To\n",
            "0  P30542  ENSG00000163485.18\n",
            "1  Q16678  ENSG00000138061.13\n",
            "2  Q02880  ENSG00000077097.17\n",
            "failed: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "get_uniprot_by_gene.py\n",
        "\n",
        "Ask the user for a gene name (e.g. \"CD45\" or \"PTPRC\"), treat that input as a gene name,\n",
        "query UniProt for the top human (9606) reviewed hit, and print:\n",
        "  - gene name (what user entered)\n",
        "  - UniProt accession (primary accession)\n",
        "  - entry name (e.g. PTPRC_HUMAN)\n",
        "  - sequence (FASTA-style wrapped at 60 chars)\n",
        "\n",
        "Requires: requests\n",
        "Install: pip install requests\n",
        "\"\"\"\n",
        "\n",
        "from typing import Optional, Dict\n",
        "import requests\n",
        "import sys\n",
        "\n",
        "UNIPROT_SEARCH_URL = \"https://rest.uniprot.org/uniprotkb/search\"\n",
        "UNIPROT_ENTRY_URL = \"https://rest.uniprot.org/uniprotkb/\"\n",
        "\n",
        "def build_gene_query(gene: str) -> str:\n",
        "    \"\"\"Build a UniProt query that treats the input as a gene name and restricts to human reviewed entries.\"\"\"\n",
        "    g = gene.strip()\n",
        "    # Use gene_exact and gene to increase chance of matching official gene names and synonyms.\n",
        "    # Require human (9606) and reviewed (Swiss-Prot).\n",
        "    return f'(gene_exact:{g} OR gene:{g}) AND organism_id:9606 AND reviewed:true'\n",
        "\n",
        "def query_uniprot_first_hit_by_gene(gene: str, size: int = 1) -> Optional[Dict]:\n",
        "    \"\"\"Query UniProtKB for the given gene (human, reviewed) and return the first result JSON dict or None.\"\"\"\n",
        "    query = build_gene_query(gene)\n",
        "    params = {\n",
        "        \"query\": query,\n",
        "        \"format\": \"json\",\n",
        "        \"size\": size\n",
        "    }\n",
        "    resp = requests.get(UNIPROT_SEARCH_URL, params=params, timeout=15)\n",
        "    resp.raise_for_status()\n",
        "    data = resp.json()\n",
        "    results = data.get(\"results\", [])\n",
        "    if not results:\n",
        "        return None\n",
        "    return results[0]\n",
        "\n",
        "def extract_accession_and_entry_name(result: Dict) -> (Optional[str], Optional[str]):\n",
        "    \"\"\"Extract accession and entry name from a UniProt search result JSON.\"\"\"\n",
        "    accession = result.get(\"primaryAccession\") or result.get(\"accession\") or None\n",
        "    entry_name = result.get(\"uniProtkbId\") or result.get(\"id\") or result.get(\"entryName\") or None\n",
        "    return accession, entry_name\n",
        "\n",
        "def get_sequence_from_result(result: Dict) -> Optional[str]:\n",
        "    \"\"\"Try to read sequence from search result JSON if present.\"\"\"\n",
        "    seq = None\n",
        "    if \"sequence\" in result and isinstance(result[\"sequence\"], dict):\n",
        "        seq = result[\"sequence\"].get(\"value\")\n",
        "    return seq\n",
        "\n",
        "def fetch_fasta_by_accession(accession: str) -> Optional[str]:\n",
        "    \"\"\"Fetch FASTA for a given accession from UniProt and return the plain sequence (no header).\"\"\"\n",
        "    url = f\"{UNIPROT_ENTRY_URL}{accession}.fasta\"\n",
        "    resp = requests.get(url, timeout=15)\n",
        "    if resp.status_code != 200:\n",
        "        return None\n",
        "    fasta = resp.text.strip()\n",
        "    lines = fasta.splitlines()\n",
        "    if not lines:\n",
        "        return None\n",
        "    # remove header (first line) and join the rest\n",
        "    seq = \"\".join(lines[1:])\n",
        "    return seq\n",
        "\n",
        "def wrap_seq(seq: str, width: int = 60) -> str:\n",
        "    return \"\\n\".join(seq[i:i+width] for i in range(0, len(seq), width))\n",
        "\n",
        "def pretty_print(gene: str, accession: str, entry_name: str, sequence: str):\n",
        "    print(\"\\n--- UniProt (human, reviewed) lookup result ---\")\n",
        "    print(f\"Query (treated as gene name): {gene}\")\n",
        "    if entry_name:\n",
        "        print(f\"Entry name:  {entry_name}\")\n",
        "    print(f\"Accession:   {accession}\")\n",
        "    print(f\"Sequence length: {len(sequence)} aa\\n\")\n",
        "    print(f\">{accession} | {entry_name} | gene:{gene}\")\n",
        "    print(wrap_seq(sequence, 60))\n",
        "    print(\"\\n-----------------------------------------------\\n\")\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        gene_input = input(\"Enter gene name (treated as human gene name, e.g. CD45 or PTPRC): \").strip()\n",
        "        if not gene_input:\n",
        "            print(\"No gene name entered. Exiting.\")\n",
        "            return\n",
        "\n",
        "        # Query UniProt for the first human reviewed hit for this gene\n",
        "        result = query_uniprot_first_hit_by_gene(gene_input)\n",
        "        if not result:\n",
        "            # Fallback: try without reviewed:true (some rare genes might be unreviewed)\n",
        "            print(\"No reviewed human entries found. Trying without reviewed filter...\")\n",
        "            params = {\n",
        "                \"query\": f'(gene_exact:{gene_input} OR gene:{gene_input}) AND organism_id:9606',\n",
        "                \"format\": \"json\",\n",
        "                \"size\": 1\n",
        "            }\n",
        "            resp = requests.get(UNIPROT_SEARCH_URL, params=params, timeout=15)\n",
        "            resp.raise_for_status()\n",
        "            data = resp.json()\n",
        "            results = data.get(\"results\", [])\n",
        "            if not results:\n",
        "                print(f\"No UniProt hits found for gene '{gene_input}' in human (9606).\")\n",
        "                return\n",
        "            result = results[0]\n",
        "\n",
        "        accession, entry_name = extract_accession_and_entry_name(result)\n",
        "        if not accession:\n",
        "            print(\"Couldn't extract accession from UniProt result. Raw result:\")\n",
        "            print(result)\n",
        "            return\n",
        "\n",
        "        # Get sequence from result if present, otherwise fetch FASTA\n",
        "        sequence = get_sequence_from_result(result)\n",
        "        if not sequence:\n",
        "            sequence = fetch_fasta_by_accession(accession)\n",
        "        if not sequence:\n",
        "            print(f\"Could not retrieve sequence for accession {accession}.\")\n",
        "            return\n",
        "\n",
        "        pretty_print(gene_input, accession, entry_name or \"\", sequence)\n",
        "\n",
        "    except requests.HTTPError as e:\n",
        "        print(\"HTTP error while querying UniProt:\", e)\n",
        "    except requests.RequestException as e:\n",
        "        print(\"Network error while querying UniProt:\", e)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nCancelled.\")\n",
        "    except Exception as e:\n",
        "        print(\"An unexpected error occurred:\", str(e))\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWs_9P2ljrmZ",
        "outputId": "49dc6921-6760-457b-b22c-6e7dd55b1d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter gene name (treated as human gene name, e.g. CD45 or PTPRC): CD45\n",
            "\n",
            "--- UniProt (human, reviewed) lookup result ---\n",
            "Query (treated as gene name): CD45\n",
            "Entry name:  PTPRC_HUMAN\n",
            "Accession:   P08575\n",
            "Sequence length: 1306 aa\n",
            "\n",
            ">P08575 | PTPRC_HUMAN | gene:CD45\n",
            "MTMYLWLKLLAFGFAFLDTEVFVTGQSPTPSPTGLTTAKMPSVPLSSDPLPTHTTAFSPA\n",
            "STFERENDFSETTTSLSPDNTSTQVSPDSLDNASAFNTTGVSSVQTPHLPTHADSQTPSA\n",
            "GTDTQTFSGSAANAKLNPTPGSNAISDVPGERSTASTFPTDPVSPLTTTLSLAHHSSAAL\n",
            "PARTSNTTITANTSDAYLNASETTTLSPSGSAVISTTTIATTPSKPTCDEKYANITVDYL\n",
            "YNKETKLFTAKLNVNENVECGNNTCTNNEVHNLTECKNASVSISHNSCTAPDKTLILDVP\n",
            "PGVEKFQLHDCTQVEKADTTICLKWKNIETFTCDTQNITYRFQCGNMIFDNKEIKLENLE\n",
            "PEHEYKCDSEILYNNHKFTNASKIIKTDFGSPGEPQIIFCRSEAAHQGVITWNPPQRSFH\n",
            "NFTLCYIKETEKDCLNLDKNLIKYDLQNLKPYTKYVLSLHAYIIAKVQRNGSAAMCHFTT\n",
            "KSAPPSQVWNMTVSMTSDNSMHVKCRPPRDRNGPHERYHLEVEAGNTLVRNESHKNCDFR\n",
            "VKDLQYSTDYTFKAYFHNGDYPGEPFILHHSTSYNSKALIAFLAFLIIVTSIALLVVLYK\n",
            "IYDLHKKRSCNLDEQQELVERDDEKQLMNVEPIHADILLETYKRKIADEGRLFLAEFQSI\n",
            "PRVFSKFPIKEARKPFNQNKNRYVDILPYDYNRVELSEINGDAGSNYINASYIDGFKEPR\n",
            "KYIAAQGPRDETVDDFWRMIWEQKATVIVMVTRCEEGNRNKCAEYWPSMEEGTRAFGDVV\n",
            "VKINQHKRCPDYIIQKLNIVNKKEKATGREVTHIQFTSWPDHGVPEDPHLLLKLRRRVNA\n",
            "FSNFFSGPIVVHCSAGVGRTGTYIGIDAMLEGLEAENKVDVYGYVVKLRRQRCLMVQVEA\n",
            "QYILIHQALVEYNQFGETEVNLSELHPYLHNMKKRDPPSEPSPLEAEFQRLPSYRSWRTQ\n",
            "HIGNQEENKSKNRNSNVIPYDYNRVPLKHELEMSKESEHDSDESSDDDSDSEEPSKYINA\n",
            "SFIMSYWKPEVMIAAQGPLKETIGDFWQMIFQRKVKVIVMLTELKHGDQEICAQYWGEGK\n",
            "QTYGDIEVDLKDTDKSSTYTLRVFELRHSKRKDSRTVYQYQYTNWSVEQLPAEPKELISM\n",
            "IQVVKQKLPQKNSSEGNKHHKSTPLLIHCRDGSQQTGIFCALLNLLESAETEEVVDIFQV\n",
            "VKALRKARPGMVSTFEQYQFLYDVIASTYPAQNGQVKKNNHQEDKIEFDNEVDKVKQDAN\n",
            "CVNPLGAPEKLPEAKEQAEGSEPTSGTEGPEHSVNGPASPALNQGS\n",
            "\n",
            "-----------------------------------------------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}